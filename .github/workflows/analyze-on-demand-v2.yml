name: On-Demand Repository Analysis v2

on:
  workflow_dispatch:
    inputs:
      repository:
        description: 'GitHub repository (owner/repo)'
        required: true
        default: 'georgmartius/lpzrobots'
        type: string
      branch:
        description: 'Branch to analyze'
        required: false
        default: 'main'
        type: string
      max_files:
        description: 'Maximum files to analyze'
        required: false
        default: '5000'
        type: number
      callback_url:
        description: 'Webhook URL for completion notification'
        required: false
        type: string
      analysis_id:
        description: 'Custom analysis ID'
        required: false
        type: string

jobs:
  analyze:
    runs-on: ubuntu-latest
    name: Analyze C++ Repository
    
    steps:
    - name: Parse inputs
      run: |
        echo "🎯 Starting analysis with inputs:"
        echo "Repository: ${{ github.event.inputs.repository }}"
        echo "Branch: ${{ github.event.inputs.branch }}"
        echo "Max files: ${{ github.event.inputs.max_files }}"
        
        # Set environment variables
        echo "REPO=${{ github.event.inputs.repository }}" >> $GITHUB_ENV
        echo "BRANCH=${{ github.event.inputs.branch || 'main' }}" >> $GITHUB_ENV
        echo "MAX_FILES=${{ github.event.inputs.max_files || '5000' }}" >> $GITHUB_ENV
        echo "CALLBACK_URL=${{ github.event.inputs.callback_url }}" >> $GITHUB_ENV
        
        # Generate or use provided analysis ID
        if [ -n "${{ github.event.inputs.analysis_id }}" ]; then
          echo "ANALYSIS_ID=${{ github.event.inputs.analysis_id }}" >> $GITHUB_ENV
        else
          # Generate timestamp-based ID with random suffix
          TIMESTAMP=$(date +%s)
          RANDOM_SUFFIX=$(openssl rand -hex 4)
          echo "ANALYSIS_ID=${TIMESTAMP}-${RANDOM_SUFFIX}" >> $GITHUB_ENV
        fi
        
        # Set workflow URL for status tracking
        echo "WORKFLOW_URL=${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" >> $GITHUB_ENV

    - name: Checkout CPPCheck Studio
      uses: actions/checkout@v4
      with:
        path: cppcheck-studio

    - name: Setup environment
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y cppcheck jq
        
        cd cppcheck-studio/cppcheck-dashboard-generator
        npm ci
        npm run build
        sudo npm link
        cd ../..

    - name: Clone and analyze repository
      id: analyze
      run: |
        echo "🔍 Analyzing repository: ${{ env.REPO }}"
        
        # Get default branch if not specified
        if [ -z "${{ env.BRANCH }}" ] || [ "${{ env.BRANCH }}" = "main" ]; then
          DEFAULT_BRANCH=$(curl -s https://api.github.com/repos/${{ env.REPO }} | jq -r .default_branch)
          if [ "$DEFAULT_BRANCH" != "null" ] && [ -n "$DEFAULT_BRANCH" ]; then
            BRANCH=$DEFAULT_BRANCH
          else
            BRANCH="${{ env.BRANCH }}"
          fi
        else
          BRANCH="${{ env.BRANCH }}"
        fi
        
        echo "📌 Branch: $BRANCH"
        MAX_FILES=$(echo "${{ env.MAX_FILES }}" | cut -d. -f1)
        echo "MAX_FILES_INT=$MAX_FILES" >> $GITHUB_ENV
        echo "📄 Max files: $MAX_FILES"
        
        # Clone target repository
        git clone --depth 1 --branch $BRANCH \
          https://github.com/${{ env.REPO }}.git target-repo || {
          echo "❌ Failed to clone repository ${{ env.REPO }} (branch: $BRANCH)"
          echo "Please check:"
          echo "  - Repository exists and is public"
          echo "  - Branch name is correct"
          exit 1
        }
        
        cd target-repo
        COMMIT_SHA=$(git rev-parse --short HEAD)
        echo "COMMIT_SHA=${COMMIT_SHA}" >> $GITHUB_ENV
        
        # Log repository info
        echo "📦 Successfully cloned: ${{ env.REPO }}"
        echo "🔖 Commit: ${COMMIT_SHA}"
        echo "📁 Current directory: $(pwd)"
        echo "📊 Repository structure:"
        ls -la | head -10
        
        # Find C++ files
        find . -type f \( -name "*.cpp" -o -name "*.cc" -o -name "*.cxx" -o -name "*.c" -o -name "*.h" -o -name "*.hpp" \) \
          -not -path "*/build/*" \
          -not -path "*/.git/*" \
          -not -path "*/vendor/*" \
          -not -path "*/third_party/*" \
          | head -n $MAX_FILES > cpp_files.txt
        
        FILE_COUNT=$(wc -l < cpp_files.txt)
        echo "FILE_COUNT=${FILE_COUNT}" >> $GITHUB_ENV
        
        if [ ${FILE_COUNT} -eq 0 ]; then
          echo "❌ No C++ files found in repository"
          exit 1
        fi
        
        echo "✅ Found ${FILE_COUNT} C++ files to analyze"
        
        # Show sample of files being analyzed
        echo "📋 Sample files:"
        head -10 cpp_files.txt
        
        # Run cppcheck
        echo "🔧 Running cppcheck analysis..."
        cppcheck \
          --enable=all \
          --inconclusive \
          --suppress=missingIncludeSystem \
          --std=c++17 \
          --xml \
          --xml-version=2 \
          --file-list=cpp_files.txt \
          -j $(nproc) \
          2> ../cppcheck-results.xml || true
        
        cd ..
        
        # Convert to JSON
        echo "📊 Converting results to JSON..."
        python3 cppcheck-studio/xml2json-simple.py cppcheck-results.xml > analysis.json
        
        # Get issue count
        ISSUE_COUNT=$(python3 -c "import json; print(len(json.load(open('analysis.json'))['issues']))")
        echo "ISSUE_COUNT=${ISSUE_COUNT}" >> $GITHUB_ENV
        echo "📈 Total issues found: ${ISSUE_COUNT}"
        
        # Add code context
        echo "📝 Adding code context..."
        cd target-repo
        python3 ../cppcheck-studio/add-code-context.py ../analysis.json ../analysis-with-context.json
        cd ..
        
        # Verify the data
        echo "🔍 Verifying analysis data..."
        node cppcheck-studio/scripts/verify-dashboard.js analysis-with-context.json || true

    - name: Create real-time status update
      if: always()
      run: |
        # Create status directory
        mkdir -p output/status
        
        # Create live status file with more details
        cat > output/status/${{ env.ANALYSIS_ID }}.json << EOF
        {
          "analysis_id": "${{ env.ANALYSIS_ID }}",
          "repository": "${{ env.REPO }}",
          "branch": "${{ env.BRANCH }}",
          "commit": "${{ env.COMMIT_SHA }}",
          "status": "running",
          "workflow_run_id": "${{ github.run_id }}",
          "workflow_run_url": "${{ env.WORKFLOW_URL }}",
          "started_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "updated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "progress": {
            "files_found": ${{ env.FILE_COUNT || 0 }},
            "files_analyzed": ${{ env.FILE_COUNT || 0 }},
            "issues_found": ${{ env.ISSUE_COUNT || 0 }},
            "current_step": "Generating dashboard"
          },
          "message": "Analysis complete. Generating interactive dashboard..."
        }
        EOF

    - name: Generate enhanced dashboard
      run: |
        # Create output directory
        mkdir -p output
        
        # Show what we're working with
        echo "📁 Current directory: $(pwd)"
        echo "📄 Analysis file size: $(ls -lh analysis-with-context.json | awk '{print $5}')"
        echo "📊 First 5 issues from analysis:"
        python3 -c "
import json
with open('analysis-with-context.json') as f:
    data = json.load(f)
    issues = data.get('issues', [])
    print(f'Total issues: {len(issues)}')
    for i, issue in enumerate(issues[:5]):
        print(f'\\nIssue {i+1}:')
        print(f'  File: {issue.get(\"file\", \"N/A\")}')
        print(f'  Line: {issue.get(\"line\", \"N/A\")}')
        print(f'  Severity: {issue.get(\"severity\", \"N/A\")}')
        print(f'  Message: {issue.get(\"message\", \"N/A\")[:80]}...')
        print(f'  Has context: {\"code_context\" in issue}')
"
        
        # Generate dashboard with enhanced features
        PROJECT_NAME="${{ env.REPO }}"
        echo "🎨 Generating dashboard for ${PROJECT_NAME}..."
        
        cppcheck-dashboard \
          analysis-with-context.json \
          output/dashboard-${{ env.ANALYSIS_ID }}.html \
          --title "${PROJECT_NAME} Analysis" \
          --project "${PROJECT_NAME} (${{ env.COMMIT_SHA }})" \
          --verbose
        
        # Verify the generated dashboard
        echo "✅ Verifying generated dashboard..."
        node cppcheck-studio/scripts/verify-dashboard.js output/dashboard-${{ env.ANALYSIS_ID }}.html || true
        
        # Generate summary
        python3 cppcheck-studio/scripts/generate-summary.py analysis.json > output/summary.txt
        
        # Generate detailed report
        python3 cppcheck-studio/scripts/generate-detailed-report.py analysis.json > output/report.md
        
        # Create enhanced metadata with direct links
        DASHBOARD_URL="https://jerryzhao173985.github.io/cppcheck-studio/results/${{ env.ANALYSIS_ID }}/index.html"
        cat > output/metadata.json << EOF
        {
          "analysis_id": "${{ env.ANALYSIS_ID }}",
          "repository": "${{ env.REPO }}",
          "branch": "${{ env.BRANCH }}",
          "commit": "${{ env.COMMIT_SHA }}",
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "files_analyzed": ${{ env.FILE_COUNT }},
          "issues_found": ${{ env.ISSUE_COUNT }},
          "max_files": ${{ env.MAX_FILES_INT }},
          "dashboard_url": "${DASHBOARD_URL}",
          "workflow_url": "${{ env.WORKFLOW_URL }}",
          "status": "completed",
          "links": {
            "dashboard": "${DASHBOARD_URL}",
            "workflow": "${{ env.WORKFLOW_URL }}",
            "api_status": "https://jerryzhao173985.github.io/cppcheck-studio/api/status/${{ env.ANALYSIS_ID }}.json",
            "api_metadata": "https://jerryzhao173985.github.io/cppcheck-studio/api/analyses/${{ env.ANALYSIS_ID }}.json"
          }
        }
        EOF

    - name: Upload results as artifacts
      uses: actions/upload-artifact@v4
      with:
        name: analysis-${{ env.ANALYSIS_ID }}
        path: |
          output/dashboard-*.html
          output/summary.txt
          output/report.md
          output/metadata.json
          analysis.json
          analysis-with-context.json

    - name: Deploy results and update status
      if: github.ref == 'refs/heads/main'
      run: |
        # Clone the repo with authentication
        git clone https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}.git deploy-repo
        cd deploy-repo
        
        # Create directories
        mkdir -p docs/results/${{ env.ANALYSIS_ID }}
        mkdir -p docs/api/status
        mkdir -p docs/api/analyses
        
        # Copy dashboard and metadata
        cp ../output/dashboard-${{ env.ANALYSIS_ID }}.html docs/results/${{ env.ANALYSIS_ID }}/index.html
        cp ../output/metadata.json docs/results/${{ env.ANALYSIS_ID }}/
        cp ../output/metadata.json docs/api/analyses/${{ env.ANALYSIS_ID }}.json
        
        # Create final status with complete information
        cat > docs/api/status/${{ env.ANALYSIS_ID }}.json << EOF
        {
          "analysis_id": "${{ env.ANALYSIS_ID }}",
          "repository": "${{ env.REPO }}",
          "branch": "${{ env.BRANCH }}",
          "commit": "${{ env.COMMIT_SHA }}",
          "status": "completed",
          "workflow_run_id": "${{ github.run_id }}",
          "workflow_run_url": "${{ env.WORKFLOW_URL }}",
          "started_at": "$(date -u -d '5 minutes ago' +%Y-%m-%dT%H:%M:%SZ)",
          "completed_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "files_analyzed": ${{ env.FILE_COUNT }},
          "issues_found": ${{ env.ISSUE_COUNT }},
          "dashboard_url": "https://jerryzhao173985.github.io/cppcheck-studio/results/${{ env.ANALYSIS_ID }}/index.html",
          "message": "Analysis completed successfully! View the interactive dashboard to explore all ${{ env.ISSUE_COUNT }} issues found."
        }
        EOF
        
        # Update gallery.json with the new analysis
        if [ -f docs/gallery.json ]; then
          # Add new analysis to gallery
          python3 << 'PYTHON_SCRIPT'
import json
from datetime import datetime

gallery_path = 'docs/gallery.json'
with open(gallery_path) as f:
    gallery = json.load(f)

new_analysis = {
    "id": "${{ env.ANALYSIS_ID }}",
    "repository": "${{ env.REPO }}",
    "branch": "${{ env.BRANCH }}",
    "commit": "${{ env.COMMIT_SHA }}",
    "timestamp": datetime.utcnow().isoformat() + "Z",
    "files_analyzed": ${{ env.FILE_COUNT }},
    "issues_found": ${{ env.ISSUE_COUNT }},
    "dashboard_url": "https://jerryzhao173985.github.io/cppcheck-studio/results/${{ env.ANALYSIS_ID }}/index.html",
    "workflow_url": "${{ env.WORKFLOW_URL }}"
}

# Add to beginning of analyses list
gallery['analyses'].insert(0, new_analysis)

# Keep only last 50 analyses
gallery['analyses'] = gallery['analyses'][:50]

# Update metadata
gallery['total_analyses'] = len(gallery['analyses'])
gallery['last_updated'] = datetime.utcnow().isoformat() + "Z"

with open(gallery_path, 'w') as f:
    json.dump(gallery, f, indent=2)
PYTHON_SCRIPT
        fi
        
        # Commit and push
        git config user.name "GitHub Actions"
        git config user.email "actions@github.com"
        git add .
        git commit -m "Add analysis results for ${{ env.REPO }} (#${{ env.ANALYSIS_ID }})"
        git push

    - name: Send callback notification
      if: always() && env.CALLBACK_URL != ''
      run: |
        # Prepare callback payload
        DASHBOARD_URL="https://jerryzhao173985.github.io/cppcheck-studio/results/${{ env.ANALYSIS_ID }}/index.html"
        
        PAYLOAD=$(cat <<EOF
        {
          "analysis_id": "${{ env.ANALYSIS_ID }}",
          "status": "${{ job.status }}",
          "repository": "${{ env.REPO }}",
          "branch": "${{ env.BRANCH }}",
          "commit": "${{ env.COMMIT_SHA }}",
          "files_analyzed": ${{ env.FILE_COUNT || 0 }},
          "issues_found": ${{ env.ISSUE_COUNT || 0 }},
          "dashboard_url": "${DASHBOARD_URL}",
          "workflow_url": "${{ env.WORKFLOW_URL }}",
          "completed_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        }
        EOF
        )
        
        # Send callback
        curl -X POST "${{ env.CALLBACK_URL }}" \
          -H "Content-Type: application/json" \
          -d "$PAYLOAD" || echo "Callback notification failed"

    - name: Create enhanced job summary
      if: always()
      run: |
        DASHBOARD_URL="https://jerryzhao173985.github.io/cppcheck-studio/results/${{ env.ANALYSIS_ID }}/index.html"
        
        cat >> $GITHUB_STEP_SUMMARY << EOF
        # 📊 CPPCheck Analysis Results
        
        ## 📋 Summary
        - **Repository**: \`${{ env.REPO }}\`
        - **Branch**: \`${{ env.BRANCH }}\`
        - **Commit**: \`${{ env.COMMIT_SHA }}\`
        - **Analysis ID**: \`${{ env.ANALYSIS_ID }}\`
        
        ## 📈 Statistics
        - **Files Analyzed**: ${{ env.FILE_COUNT || 0 }}
        - **Issues Found**: ${{ env.ISSUE_COUNT || 0 }}
        
        ## 🔗 Links
        - [🎯 **View Interactive Dashboard** →](${DASHBOARD_URL})
        - [📊 View Workflow Details](${{ env.WORKFLOW_URL }})
        - [📁 View Analysis Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}#artifacts)
        
        ## 🚀 Next Steps
        1. Click the dashboard link above to explore all issues
        2. Use filters to focus on specific severity levels
        3. Click on issues to see code context
        4. Share the dashboard URL with your team
        
        ---
        *Analysis completed at $(date -u +%Y-%m-%dT%H:%M:%SZ)*
        EOF